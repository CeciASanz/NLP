{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","['gracias', 'dia', 'hoy', 'martes', 'de', 'el', 'es', 'que', 'muchas']\n"]}],"source":["def get_documentos(corpus):\n","    lista_documentos = []\n","    for document in corpus:\n","        lista_documentos.append(document.split())\n","    return lista_documentos\n","\n","def get_terminos(corpus):\n","    set_terminos = set()\n","    for document in corpus:\n","        set_terminos.update(document.split())\n","    return list(set_terminos)\n","\n","print(get_documentos(corpus))\n","print(get_terminos(corpus))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["def one_hot_encoding_text(vocabulario, lista_textos):\n","    matrix_ohe = []\n","    for document in lista_textos:\n","        row_ohe = []\n","        for termino in vocabulario:\n","            row_ohe.append(1) if termino in document else row_ohe.append(0)\n","        matrix_ohe.append(row_ohe)\n","    return matrix_ohe"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["[[0, 1, 1, 0, 0, 0, 1, 1, 0],\n"," [0, 1, 1, 1, 1, 1, 1, 0, 0],\n"," [1, 0, 0, 1, 0, 0, 0, 0, 1]]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["vocabulario = get_terminos(corpus)\n","lista_textos = get_documentos(corpus)\n","one_hot_encoding_text(vocabulario, lista_textos)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[],"source":["def get_frequency_vector(vocabulario, lista_textos):\n","    frequency_vector = []\n","    for document in lista_textos:\n","        vector = [0 for _ in range(len(vocabulario))]\n","        for word in document:\n","            word_index  = vocabulario.index(word)\n","            if word_index >= 0:\n","                vector[word_index]+=1\n","        frequency_vector.append(vector)\n","    return frequency_vector"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["[[0, 1, 1, 0, 0, 0, 1, 1, 0],\n"," [0, 1, 1, 2, 1, 1, 1, 0, 0],\n"," [1, 0, 0, 1, 0, 0, 0, 0, 1]]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["get_frequency_vector(vocabulario, lista_textos)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["def get_tf_idf(vocabulario, lista_textos):\n","    return np.log10(len(lista_textos)/np.sum(one_hot_encoding_text(vocabulario, lista_textos), axis=0))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.47712125, 0.17609126, 0.17609126, 0.17609126, 0.47712125,\n","       0.47712125, 0.17609126, 0.47712125, 0.47712125])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["get_tf_idf(vocabulario, lista_textos)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def similarity(corpus, index):\n","    vocabulario = get_terminos(corpus)\n","    lista_textos = get_documentos(corpus)\n","    ohe = one_hot_encoding_text(vocabulario, lista_textos)\n","    sim_list = []\n","    for i in range(len(ohe)):\n","        if i != index:\n","            sim_list.append([corpus[i], cosine_similarity(ohe[index], ohe[i])])\n","    return sorted(sim_list, key=lambda x: x[1], reverse=True)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["[['que dia es hoy', 0.6123724356957946],\n"," ['martes muchas gracias', 0.23570226039551587]]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["similarity(corpus, 1)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
